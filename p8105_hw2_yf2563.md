p8105\_hw2\_yf2563
================
Yatong Feng
9/30/2020

``` r
#load packages
library(tidyverse)
library(readxl)
```

## Problem 1

  - specify the sheet in the Excel file and to omit non-data entries
    (rows with notes / figures; columns containing notes) using
    arguments in read\_excel
  - use reasonable variable names
  - omit rows that do not include dumpster-specific data
  - round the number of sports balls to the nearest integer and converts
    the result to an integer variable (using as.integer)

First, define a path and read the dataset

``` r
path_to_data = './data/Trash-Wheel-Collection-Totals-8-6-19.xlsx'
trashwheel_df = 
    read_xlsx(
        path = path_to_data,
        sheet = "Mr. Trash Wheel",
        range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster) %>% 
    mutate(
        sports_balls = round(sports_balls, digits = 0),
        sports_balls = as.integer(sports_balls)
    ) %>% 
  relocate(dumpster,month,year,date,sports_balls)
trashwheel_df
```

    ## # A tibble: 344 x 14
    ##    dumpster month  year date                sports_balls weight_tons
    ##       <dbl> <chr> <dbl> <dttm>                     <int>       <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00            7        4.31
    ##  2        2 May    2014 2014-05-16 00:00:00            5        2.74
    ##  3        3 May    2014 2014-05-16 00:00:00            6        3.45
    ##  4        4 May    2014 2014-05-17 00:00:00            6        3.1 
    ##  5        5 May    2014 2014-05-17 00:00:00            7        4.06
    ##  6        6 May    2014 2014-05-20 00:00:00            5        2.71
    ##  7        7 May    2014 2014-05-21 00:00:00            3        1.91
    ##  8        8 May    2014 2014-05-28 00:00:00            6        3.7 
    ##  9        9 June   2014 2014-06-05 00:00:00            6        2.52
    ## 10       10 June   2014 2014-06-11 00:00:00            7        3.76
    ## # … with 334 more rows, and 8 more variables: volume_cubic_yards <dbl>,
    ## #   plastic_bottles <dbl>, polystyrene <dbl>, cigarette_butts <dbl>,
    ## #   glass_bottles <dbl>, grocery_bags <dbl>, chip_bags <dbl>,
    ## #   homes_powered <dbl>

Read and clean precipitation data for 2017 and 2018.

  - omit rows without precipitation data and add a variable year

<!-- end list -->

``` r
# data for 2018
precip_2018 = 
    read_excel(
        path = path_to_data,
        sheet = "2018 Precipitation",
        range = "A2:B14"
    ) %>% 
    janitor::clean_names() %>% 
    drop_na(total) %>% 
    mutate(year = 2018) %>% 
    relocate(year)
```

``` r
# data for 2017
precip_2017 = 
    read_excel(
        path = path_to_data,
        sheet = "2017 Precipitation",
        range = "A2:B14"
    ) %>% 
    janitor::clean_names() %>% 
    drop_na(total) %>% 
    mutate(year = 2017) %>% 
    relocate(year)
```

  - combine precipitation datasets and convert month to a character
    variable

<!-- end list -->

``` r
month_df = 
    tibble(
        month = 1:12,
        month_name = month.name
    )
precip_df = 
    bind_rows(precip_2018, precip_2017)

precip_df =
    left_join(precip_df, month_df, by = "month") %>% 
  select(-month) %>% 
  rename(month = month_name) %>%
  relocate(year, month)

precip_df
```

    ## # A tibble: 24 x 3
    ##     year month     total
    ##    <dbl> <chr>     <dbl>
    ##  1  2018 January    0.94
    ##  2  2018 February   4.8 
    ##  3  2018 March      2.69
    ##  4  2018 April      4.69
    ##  5  2018 May        9.27
    ##  6  2018 June       4.77
    ##  7  2018 July      10.2 
    ##  8  2018 August     6.45
    ##  9  2018 September 10.5 
    ## 10  2018 October    2.12
    ## # … with 14 more rows

### Summary of the data:

``` r
summary(trashwheel_df)
```

    ##     dumpster         month                year     
    ##  Min.   :  1.00   Length:344         Min.   :2014  
    ##  1st Qu.: 86.75   Class :character   1st Qu.:2015  
    ##  Median :172.50   Mode  :character   Median :2017  
    ##  Mean   :172.50                      Mean   :2016  
    ##  3rd Qu.:258.25                      3rd Qu.:2018  
    ##  Max.   :344.00                      Max.   :2019  
    ##       date                      sports_balls    weight_tons   
    ##  Min.   :2014-05-16 00:00:00   Min.   : 0.00   Min.   :0.960  
    ##  1st Qu.:2015-07-05 00:00:00   1st Qu.: 5.00   1st Qu.:2.757  
    ##  Median :2017-03-31 00:00:00   Median : 8.00   Median :3.265  
    ##  Mean   :2016-12-23 10:57:12   Mean   :11.81   Mean   :3.263  
    ##  3rd Qu.:2018-05-19 18:00:00   3rd Qu.:16.00   3rd Qu.:3.772  
    ##  Max.   :2019-06-17 00:00:00   Max.   :56.00   Max.   :5.620  
    ##  volume_cubic_yards plastic_bottles   polystyrene   cigarette_butts 
    ##  Min.   : 7.00      Min.   : 210.0   Min.   : 320   Min.   :   980  
    ##  1st Qu.:15.00      1st Qu.: 957.5   1st Qu.:1065   1st Qu.:  7000  
    ##  Median :15.00      Median :1835.0   Median :2075   Median : 19000  
    ##  Mean   :15.54      Mean   :1873.2   Mean   :2139   Mean   : 30754  
    ##  3rd Qu.:16.00      3rd Qu.:2552.5   3rd Qu.:3120   3rd Qu.: 38000  
    ##  Max.   :20.00      Max.   :5960.0   Max.   :6540   Max.   :310000  
    ##  glass_bottles     grocery_bags    chip_bags      homes_powered  
    ##  Min.   :  0.00   Min.   :  50   Min.   : 230.0   Min.   : 0.00  
    ##  1st Qu.: 10.00   1st Qu.: 600   1st Qu.: 977.5   1st Qu.:35.62  
    ##  Median : 21.50   Median :1050   Median :1630.0   Median :51.42  
    ##  Mean   : 25.36   Mean   :1311   Mean   :1780.3   Mean   :43.83  
    ##  3rd Qu.: 38.00   3rd Qu.:1912   3rd Qu.:2490.0   3rd Qu.:59.50  
    ##  Max.   :110.00   Max.   :3750   Max.   :5085.0   Max.   :93.67

``` r
summary(precip_df)
```

    ##       year         month               total       
    ##  Min.   :2017   Length:24          Min.   : 0.000  
    ##  1st Qu.:2017   Class :character   1st Qu.: 1.827  
    ##  Median :2018   Mode  :character   Median : 4.215  
    ##  Mean   :2018                      Mean   : 4.303  
    ##  3rd Qu.:2018                      3rd Qu.: 6.195  
    ##  Max.   :2018                      Max.   :10.470

The first dataset is about the information from the Mr. Trashwheel trash
collector in Baltimore, Maryland:

  - After filtering, there are a total of 344 rows and 14 columns.
  - The variables include dumpster, month, year, date, sports\_balls,
    weight\_tons, volume\_cubic\_yards, plastic\_bottles, polystyrene,
    cigarette\_butts, glass\_bottles, grocery\_bags, chip\_bags,
    homes\_powered

The second dataset is about the month precipitation in 2017 and 2018:

  - After filtering, there are a total of 24 rows and 3 columns.
  - The variables include year, month, total
  - The median number of sports balls found in a dumpster in 2017 was 8
  - The median number of sports balls found in a dumpster in 2018 was 4
  - The total precipitation in 2018 was 70.33 inches.
  - The total precipitation in 2017 was 32.93 inches.

## Problem 2

Read and clean the data:

  - retain line, station, name, station latitude / longitude, routes
    served, entry, vending, entrance type, and ADA compliance
  - Convert the entry variable from character (YES vs NO) to a logical
    variable (the ifelse or recode function may be useful).

<!-- end list -->

``` r
path_prob2 = './data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv'

subway_df =
  read_csv(path_prob2) %>%
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>%
  mutate(entry = recode(entry, "YES" = T, "NO" = F))

subway_df
```

    ## # A tibble: 1,868 x 19
    ##    line  station_name station_latitude station_longitu… route1 route2 route3
    ##    <chr> <chr>                   <dbl>            <dbl> <chr>  <chr>  <chr> 
    ##  1 4 Av… 25th St                  40.7            -74.0 R      <NA>   <NA>  
    ##  2 4 Av… 25th St                  40.7            -74.0 R      <NA>   <NA>  
    ##  3 4 Av… 36th St                  40.7            -74.0 N      R      <NA>  
    ##  4 4 Av… 36th St                  40.7            -74.0 N      R      <NA>  
    ##  5 4 Av… 36th St                  40.7            -74.0 N      R      <NA>  
    ##  6 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  7 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  8 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  9 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ## 10 4 Av… 53rd St                  40.6            -74.0 R      <NA>   <NA>  
    ## # … with 1,858 more rows, and 12 more variables: route4 <chr>, route5 <chr>,
    ## #   route6 <chr>, route7 <chr>, route8 <dbl>, route9 <dbl>, route10 <dbl>,
    ## #   route11 <dbl>, entry <lgl>, vending <chr>, entrance_type <chr>, ada <lgl>

### Summary for the NYC subway data

The data set contains information related to each entrance and exit for
each subway station in NYC:

  - The data cleaning procedure include:
      - Read the data through read\_csv()
      - Clean the column names through clean\_names()
      - Retain the required variables through select()
      - Convert the entry variable from character (YES vs NO) to a
        logical variable through recode()
  - After filtering, there are a total of 1868 rows and 19 columns, thus
    the dimension of the dataset is 1868, 19.
  - The variables include line, station\_name, station\_latitude,
    station\_longitude, route1, route2, route3, route4, route5, route6,
    route7, route8, route9, route10, route11, entry, vending,
    entrance\_type, ada
  - This data is not tidy since the data type of variables route 1 - 11
    contains both chr and dbl

### Answer the following questions using these data:

##### 1\. How many distinct stations are there?

``` r
question1_df =
  subway_df %>% 
  distinct(line, station_name, .keep_all = T)
```

Thus, there are 465 distinct stations

##### 2\. How many stations are ADA compliant?

``` r
question2_df = 
  question1_df %>% 
  filter(ada == TRUE)
```

Thus, 84 stations are ADA compliant

##### 3\. What proportion of station entrances / exits without vending allow entrance?

``` r
question3_without_vending = 
  subway_df %>% 
  filter(vending == "NO")

question3_without_vending_allow_entrance = 
  subway_df %>% 
  filter(vending == "NO") %>% 
  filter(entry == T)

question3_proportion = nrow(question3_without_vending_allow_entrance) / nrow(question3_without_vending)
```

Thus, the proportion of station entrances / exits without vending allow
entrance is 0.3770492

Reformat data so that route number and route name are distinct
variables.

``` r
reformat_subway_df =
  question1_df %>%
  mutate(route8 = as.character(route8),
         route9 = as.character(route9),
         route10 = as.character(route10),
         route11 = as.character(route11)) %>%
  pivot_longer(col = route1:route11,
               names_to = "route_name", 
               values_to = "route_number") %>%
  arrange(route_name, route_number)
reformat_subway_df
```

    ## # A tibble: 5,115 x 10
    ##    line  station_name station_latitude station_longitu… entry vending
    ##    <chr> <chr>                   <dbl>            <dbl> <lgl> <chr>  
    ##  1 Broa… 103rd St                 40.8            -74.0 TRUE  YES    
    ##  2 Broa… 116th St-Co…             40.8            -74.0 TRUE  YES    
    ##  3 Broa… 125th St                 40.8            -74.0 TRUE  YES    
    ##  4 Broa… 137th St-Ci…             40.8            -74.0 TRUE  YES    
    ##  5 Broa… 145th St                 40.8            -74.0 TRUE  YES    
    ##  6 Broa… 157th St                 40.8            -73.9 TRUE  YES    
    ##  7 Broa… 181st St                 40.8            -73.9 TRUE  YES    
    ##  8 Broa… 18th St                  40.7            -74.0 TRUE  YES    
    ##  9 Broa… 191st St                 40.9            -73.9 TRUE  YES    
    ## 10 Broa… 207th St                 40.9            -73.9 TRUE  YES    
    ## # … with 5,105 more rows, and 4 more variables: entrance_type <chr>, ada <lgl>,
    ## #   route_name <chr>, route_number <chr>

##### 4\. How many distinct stations serve the A train?

``` r
question4_df =
  question1_df %>% 
  filter(route1 == "A"|route2 =="A"|route3 == "A"|route4 =="A"|
           route5 == "A"|route6 =="A"|route7 == "A"|route8 =="A"|
           route9 == "A"|route10 =="A"|route11 =="A")
```

Thus, there are 60 distinct stations serve the A train

##### 5.Of the stations that serve the A train, how many are ADA compliant?

``` r
question5_df = 
  question4_df %>% 
  filter(ada == TRUE)
```

Thus, Of the stations that serve the A train, 17 are ADA compliant.

## Problem 3

First, clean the data in pols-month.csv.

  - Use separate() to break up the variable mon into integer variables
    year, month, and day
  - replace month number with month name
  - create a president variable taking values gop and dem, and remove
    prez\_dem and prez\_gop; and remove the day variable.

<!-- end list -->

``` r
path_pols_month = "./data/pols-month.csv"

pols_month_df = 
  read_csv(path_pols_month) %>%
  janitor::clean_names() %>%
  separate(mon,c("year","month","day")) %>%
  mutate(year = as.integer(year), month = as.integer(month), day = as.integer(day)) %>%
  mutate(month = recode(month, `1` = "Jan", `2` = "Feb", `3` = "Mar", `4` = "Apr", `5` = "May" , `6`= "Jun", `7` = "Jul", `8` = "Aug", `9` = "Sep", `10` = "Oct", `11` = "Nov", `12` = "Dec")) %>%
  mutate(president = ifelse(prez_dem == 1, "dem", "gop")) %>%
  select(-prez_dem,-prez_gop,-day) %>%
  arrange(desc(row_number()))

pols_month_df
```

    ## # A tibble: 822 x 9
    ##     year month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <int> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1  2015 Jun        31      54     246      18      44     188 dem      
    ##  2  2015 May        31      54     245      18      44     188 dem      
    ##  3  2015 Apr        31      54     244      18      44     188 dem      
    ##  4  2015 Mar        31      54     245      18      44     188 dem      
    ##  5  2015 Feb        31      54     245      18      44     188 dem      
    ##  6  2015 Jan        31      54     245      18      44     188 dem      
    ##  7  2014 Dec        29      45     235      21      53     201 dem      
    ##  8  2014 Nov        29      45     235      21      53     201 dem      
    ##  9  2014 Oct        29      45     234      21      53     199 dem      
    ## 10  2014 Sep        29      45     234      21      53     199 dem      
    ## # … with 812 more rows

Second, clean the data in snp.csv using a similar process to the above.

  - For consistency across datasets, arrange according to year and
    month, and organize so that year and month are the leading columns.

<!-- end list -->

``` r
path_snp = './data/snp.csv'

snp_df = 
  read_csv(path_snp) %>%
  janitor::clean_names() %>%
  separate(date,c("month","day","year")) %>%
  mutate(
    year = as.integer(year), 
    month = as.integer(month), 
    day = as.integer(day)) %>%
  mutate(month = recode(month, `1` = "Jan", `2` = "Feb", `3` = "Mar", `4` = "Apr", `5` = "May" , `6`= "Jun", `7` = "Jul", `8` = "Aug", `9` = "Sep", `10` = "Oct", `11` = "Nov", `12` = "Dec")) %>%
  select(year,month,close)

snp_df
```

    ## # A tibble: 787 x 3
    ##     year month close
    ##    <int> <chr> <dbl>
    ##  1  2015 Jul   2080.
    ##  2  2015 Jun   2063.
    ##  3  2015 May   2107.
    ##  4  2015 Apr   2086.
    ##  5  2015 Mar   2068.
    ##  6  2015 Feb   2104.
    ##  7  2015 Jan   1995.
    ##  8  2014 Dec   2059.
    ##  9  2014 Nov   2068.
    ## 10  2014 Oct   2018.
    ## # … with 777 more rows

Third, tidy the unemployment data.

  - Switching from “wide” to “long” format
  - Ensuring that key variables have the same name and take the same
    values.

<!-- end list -->

``` r
path_unemployment = './data/unemployment.csv'

unemployment_df = 
  read_csv(path_unemployment) %>%  
  pivot_longer(Jan:Dec,
               names_to = "month", 
               values_to = "unemployment") %>%
  select(year = Year, everything()) %>%
  arrange(desc(row_number()))

unemployment_df
```

    ## # A tibble: 816 x 3
    ##     year month unemployment
    ##    <dbl> <chr>        <dbl>
    ##  1  2015 Dec           NA  
    ##  2  2015 Nov           NA  
    ##  3  2015 Oct           NA  
    ##  4  2015 Sep           NA  
    ##  5  2015 Aug           NA  
    ##  6  2015 Jul           NA  
    ##  7  2015 Jun            5.3
    ##  8  2015 May            5.5
    ##  9  2015 Apr            5.4
    ## 10  2015 Mar            5.5
    ## # … with 806 more rows

Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
merge_df = left_join(pols_month_df, snp_df, by = c("year","month"))

merge_df = left_join(merge_df, unemployment_df, by = c("year","month"))

merge_df
```

    ## # A tibble: 822 x 11
    ##     year month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ##    <dbl> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ##  1  2015 Jun        31      54     246      18      44     188 dem       2063.
    ##  2  2015 May        31      54     245      18      44     188 dem       2107.
    ##  3  2015 Apr        31      54     244      18      44     188 dem       2086.
    ##  4  2015 Mar        31      54     245      18      44     188 dem       2068.
    ##  5  2015 Feb        31      54     245      18      44     188 dem       2104.
    ##  6  2015 Jan        31      54     245      18      44     188 dem       1995.
    ##  7  2014 Dec        29      45     235      21      53     201 dem       2059.
    ##  8  2014 Nov        29      45     235      21      53     201 dem       2068.
    ##  9  2014 Oct        29      45     234      21      53     199 dem       2018.
    ## 10  2014 Sep        29      45     234      21      53     199 dem       1972.
    ## # … with 812 more rows, and 1 more variable: unemployment <dbl>

### Summary for the three datasets

The first dataset is pols\_month:

  - After filtering, there are a total of 822 rows and 9 columns, thus
    the dimension is 822, 9.
  - The variables include year, month, gov\_gop, sen\_gop, rep\_gop,
    gov\_dem, sen\_dem, rep\_dem, president
  - In this dataset, ‘dem’ means democratic party, ‘gop’ means
    republican party
  - The variables of ‘gov\_gop, sen\_gop, rep\_gop, gov\_dem, sen\_dem,
    rep\_dem’ represents the number of governors or senators from
    republican or democratic party
  - The range of years is 1947, 2015

The second dataset is snp:

  - After filtering, there are a total of 787 rows and 3 columns, thus
    the dimension is 787, 3.
  - The variables include year, month, close
  - The range of years is 1950, 2015

The third dataset is about unemployment:

  - After filtering, there are a total of 816 rows and 3 columns, thus
    the dimension is 816, 3.
  - The variables include year, month, unemployment
  - The range of years is 1948, 2015

The resulting dataset is the merge of all of the three datasets:

  - After filtering, there are a total of 822 rows and 11 columns, thus
    the dimension is 822, 11.
  - The variables include year, month, gov\_gop, sen\_gop, rep\_gop,
    gov\_dem, sen\_dem, rep\_dem, president, close, unemployment
  - The range of years is 1947, 2015
